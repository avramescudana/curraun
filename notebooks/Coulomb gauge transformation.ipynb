{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coulomb gauge transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# hbar * c [GeV * fm]\n",
    "hbarc = 0.197326 \n",
    "\n",
    "# Simulation box \n",
    "L = 2      \n",
    "N = 64   \n",
    "tau_sim = 0.1     \n",
    "DTS = 4     \n",
    "\n",
    "# Glasma fields\n",
    "su_group = 'su3'\n",
    "Qs = 2        \n",
    "ns = 50    \n",
    "factor = 0.8        \n",
    "g2mu = Qs / factor     \n",
    "g = np.pi * np.sqrt(1 / np.log(Qs / 0.2))          \t\t\n",
    "mu = g2mu / g**2          \t\n",
    "ir = 0.1 * g**2 * mu         \n",
    "uv = 10.0       \n",
    "\n",
    "nevents = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Using SU(3)\n",
      "Using double precision\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# I need to add this line to ask resources from a specific GPU, which is free. Our GPU server has no queing system\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,4\"\n",
    "\n",
    "os.environ[\"MY_NUMBA_TARGET\"] = \"cuda\"\n",
    "# os.environ[\"MY_NUMBA_TARGET\"] = \"numba\"\n",
    "os.environ[\"PRECISION\"] = \"double\"\n",
    "os.environ['GAUGE_GROUP'] = su_group\n",
    "\n",
    "# Import relevant modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Glasma modules\n",
    "import curraun.core as core\n",
    "import curraun.mv as mv\n",
    "import curraun.initial as initial\n",
    "initial.DEBUG = False\n",
    "\n",
    "import curraun.su as su\n",
    "import curraun.lattice as latt\n",
    "from curraun.numba_target import use_cuda\n",
    "if use_cuda:\n",
    "    from numba import cuda\n",
    "\n",
    "import curraun.su as su\n",
    "import curraun.coulomb as coulomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate glasma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 1\n",
    "# alpha abelian should be 1/p^2_max \n",
    "# p_max = 2*pi/L in lattice units 2*pi/N\n",
    "alpha = 1/(2*np.pi/N)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.core.errors import NumbaPerformanceWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaPerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.85469173e-18-1.72965896e-01j  7.06283269e-02-1.87717302e-01j\n",
      "   1.56636718e-01-3.16982275e-02j ... -1.56636718e-01-3.16982275e-02j\n",
      "   5.38270926e-01+3.91748420e-04j -1.55040911e-17+3.72551780e-01j]\n",
      " [ 1.19397844e-17-8.91509938e-02j -5.14399081e-02-1.16977022e-02j\n",
      "  -3.12944984e-03+1.73413909e-01j ...  3.12944984e-03+1.73413909e-01j\n",
      "   5.62624765e-01+1.40433216e-01j  4.17722524e-17+3.40209293e-01j]\n",
      " [-2.82403114e-17-1.10522303e-01j -1.23936210e-01+1.65353859e-01j\n",
      "   1.01137890e-01+3.48604675e-01j ... -1.01137890e-01+3.48604675e-01j\n",
      "   1.25713684e-01+3.93379336e-01j -4.07648427e-17+3.97308797e-01j]\n",
      " ...\n",
      " [-1.46364645e-17+2.49191458e-01j -2.88404777e-02+1.09414368e-02j\n",
      "  -2.53836365e-01-2.14233716e-01j ...  2.53836365e-01-2.14233716e-01j\n",
      "  -9.14388325e-02+1.09161693e-01j -1.61191771e-18-8.20593387e-02j]\n",
      " [-1.46495423e-17+3.91690803e-01j -2.68607165e-01+2.75976059e-01j\n",
      "  -5.56149188e-01-1.82553700e-01j ...  5.56149188e-01-1.82553700e-01j\n",
      "   6.75697864e-02+1.28318980e-01j  8.62967416e-17+6.92730068e-03j]\n",
      " [-6.84341238e-17-2.47736092e-01j -2.69604952e-01+3.40412969e-01j\n",
      "  -5.46520295e-01-8.67401467e-02j ...  5.46520295e-01-8.67401467e-02j\n",
      "   2.53355903e-01-1.06614339e-01j  4.33240472e-17+3.47454648e-01j]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Simulation routine\n",
    "# def simulate(): \n",
    "\n",
    "# Derived parameters\n",
    "a = L / N\n",
    "E0 = N / L * hbarc\n",
    "DT = 1.0 / DTS\n",
    "maxt = int(tau_sim / a * DTS)\n",
    "\n",
    "# Initialize Glasma fields\n",
    "s = core.Simulation(N, DT, g)\n",
    "va = mv.wilson(s, mu=mu / E0, m=ir / E0, uv=uv / E0, num_sheets=ns)\n",
    "vb = mv.wilson(s, mu=mu / E0, m=ir / E0, uv=uv / E0, num_sheets=ns)\n",
    "initial.init(s, va, vb)\n",
    "\n",
    "coul = coulomb.CoulombGaugeTransf(s, alpha)\n",
    "\n",
    "# with tqdm(total=maxt) as pbar:\n",
    "# for t in range(maxt):      \n",
    "#TODO: evolve the glasma fields, at the moment consider only 1 evolution step\n",
    "\n",
    "# Evolve Glasma fields\n",
    "core.evolve_leapfrog(s)\n",
    "\n",
    "coulomb.gauge_transform(coul, alpha)\n",
    "delta0 = coul.delta0.copy()\n",
    "c = coul.c.copy()\n",
    "\n",
    "# print(delta0)\n",
    "print(c)\n",
    "                \n",
    "# pbar.update(1)\n",
    "\n",
    "if use_cuda:\n",
    "    cuda.current_context().deallocations.clear()\n",
    "\n",
    "# return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress various horribly long warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
