{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU gauge transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parametres and eviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# hbar * c [GeV * fm]\n",
    "hbarc = 0.197326 \n",
    "\n",
    "# Simulation box \n",
    "L = 2      \n",
    "# N = 128   \n",
    "N = 16 \n",
    "tau_sim = 1     \n",
    "DTS = 4     \n",
    "\n",
    "# Glasma fields\n",
    "su_group = 'su3'\n",
    "Qs = 2        \n",
    "ns = 50    \n",
    "factor = 0.8        \n",
    "g2mu = Qs / factor     \n",
    "g = np.pi * np.sqrt(1 / np.log(Qs / 0.2))          \t\t\n",
    "mu = g2mu / g**2          \t\n",
    "ir = 0.1 * g**2 * mu         \n",
    "uv = 10.0       \n",
    "\n",
    "# TODO: Run more events\n",
    "nevents = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# I need to add this line to ask resources from a specific GPU, which is free. Our GPU server has no queing system\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "# os.environ[\"MY_NUMBA_TARGET\"] = \"numba\"\n",
    "os.environ[\"MY_NUMBA_TARGET\"] = \"cuda\"\n",
    "os.environ[\"PRECISION\"] = \"double\"\n",
    "os.environ['GAUGE_GROUP'] = su_group\n",
    "\n",
    "# Import relevant modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Glasma modules\n",
    "import curraun.core as core\n",
    "import curraun.mv as mv\n",
    "import curraun.initial as initial\n",
    "initial.DEBUG = False\n",
    "\n",
    "import curraun.su as su\n",
    "from curraun.numba_target import use_cuda\n",
    "if use_cuda:\n",
    "    from numba import cuda\n",
    "\n",
    "import curraun.su as su\n",
    "# import curraun.lc_gauge as lc_gauge\n",
    "import curraun.lc_gauge_zindep as lc_gauge\n",
    "# Gauge transformation for U_-\n",
    "lc_gauge.LCDEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We define the simulation routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Simulation routine\n",
    "def simulate(): \n",
    "    output = {}\n",
    "    # Derived parameters\n",
    "    a = L / N\n",
    "    E0 = N / L * hbarc\n",
    "    DT = 1.0 / DTS\n",
    "    maxt = int(tau_sim / a * DTS)\n",
    "\n",
    "    #TODO: for testing only, remove after testing\n",
    "    mv.set_seed(24)\n",
    "\n",
    "    # Initialize Glasma fields\n",
    "    s = core.Simulation(N, DT, g)\n",
    "\n",
    "    va = mv.wilson(s, mu=mu / E0, m=ir / E0, uv=uv / E0, num_sheets=ns)\n",
    "    vb = mv.wilson(s, mu=mu / E0, m=ir / E0, uv=uv / E0, num_sheets=ns)\n",
    "    initial.init(s, va, vb)\n",
    "\n",
    "    # Initialize LC gauge transformation\n",
    "    nplus = maxt//DTS\n",
    "    lc = lc_gauge.LCGaugeTransf(s, nplus)\n",
    "\n",
    "    # Plus gauge link\n",
    "    # xplus=0 is not included\n",
    "    uplus_lc = su.GROUP_TYPE(np.zeros((maxt//DTS-1, N, su.GROUP_ELEMENTS)))\n",
    "    # vlc = su.GROUP_TYPE(np.zeros((nplus, nplus*N, su.GROUP_ELEMENTS)))\n",
    "    # uplus_temp = su.GROUP_TYPE(np.zeros((maxt//DTS-1, N, su.GROUP_ELEMENTS)))\n",
    "\n",
    "    if lc_gauge.LCDEBUG:\n",
    "        # xplus=0 in not included\n",
    "        # also, xplus=maxt is not included\n",
    "        uminus_lc = su.GROUP_TYPE(np.zeros((maxt//DTS-2, N, su.GROUP_ELEMENTS)))\n",
    "\n",
    "    with tqdm(total=maxt) as pbar:\n",
    "        for t in range(maxt):            \n",
    "            # Evolve Glasma fields\n",
    "            core.evolve_leapfrog(s)\n",
    "\n",
    "            if t%DTS == 0:\n",
    "                # GPU\n",
    "                xplus = t//DTS\n",
    "                lc.evolve_lc(xplus)\n",
    "\n",
    "                if xplus!= 0:\n",
    "                    uplus_lc[xplus-1] = lc.up_lc.copy()\n",
    "                    # uplus_temp[xplus-1] = lc.up_temp.copy()\n",
    "\n",
    "                if lc_gauge.LCDEBUG:\n",
    "                    if xplus != (maxt//DTS-1):\n",
    "                        uminus_lc[xplus-1] = lc.um_lc.copy()\n",
    "                    \n",
    "                # vlc[xplus] = lc.vlc1.copy()\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    if use_cuda:\n",
    "        cuda.current_context().deallocations.clear()\n",
    "\n",
    "    output[\"nplus\"] = nplus\n",
    "\n",
    "    output[\"uplus_lc\"] = uplus_lc\n",
    "    # output[\"uplus_temp\"] = uplus_temp \n",
    "    # output[\"vlc\"] = vlc \n",
    "\n",
    "    if lc_gauge.LCDEBUG:  \n",
    "        output[\"uminus_lc\"] = uminus_lc\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel xi: 228 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 231 d:  0 did not reach goal. check:  0.000983\n",
      "Kernel xi: 232 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 233 d:  0 did not reach goal. check:  0.934217\n",
      "Kernel xi: 234 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 236 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 237 d:  0 did not reach goal. check:  0.843181\n",
      "Kernel xi: 238 d:  0 did not reach goal. check:  2.358576\n",
      "Kernel xi: 241 d:  0 did not reach goal. check:  1.157817\n",
      "Kernel xi: 242 d:  0 did not reach goal. check:  1.086507\n",
      "Kernel xi: 243 d:  0 did not reach goal. check:  1.773258\n",
      "Kernel xi: 247 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 248 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 249 d:  0 did not reach goal. check:  0.096570\n",
      "Kernel xi: 253 d:  0 did not reach goal. check:  0.636997\n",
      "Kernel xi: 254 d:  0 did not reach goal. check:  0.416994\n",
      "Kernel xi: 255 d:  0 did not reach goal. check:  0.533396\n",
      "Kernel xi: 96 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 97 d:  0 did not reach goal. check:  1.178754\n",
      "Kernel xi: 101 d:  0 did not reach goal. check:  2.963470\n",
      "Kernel xi: 103 d:  0 did not reach goal. check:  0.018364\n",
      "Kernel xi: 104 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 107 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 108 d:  0 did not reach goal. check:  0.322777\n",
      "Kernel xi: 109 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 110 d:  0 did not reach goal. check:  0.000668\n",
      "Kernel xi: 112 d:  0 did not reach goal. check:  1.246753\n",
      "Kernel xi: 114 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 115 d:  0 did not reach goal. check:  0.708489\n",
      "Kernel xi: 118 d:  0 did not reach goal. check:  0.052575\n",
      "Kernel xi: 119 d:  0 did not reach goal. check:  0.146152\n",
      "Kernel xi: 122 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 123 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 124 d:  0 did not reach goal. check:  0.019707\n",
      "Kernel xi: 125 d:  0 did not reach goal. check:  0.094324\n",
      "Kernel xi: 128 d:  0 did not reach goal. check:  0.000113\n",
      "Kernel xi: 129 d:  0 did not reach goal. check:  0.133841\n",
      "Kernel xi: 130 d:  0 did not reach goal. check:  0.000768\n",
      "Kernel xi: 131 d:  0 did not reach goal. check:  0.009965\n",
      "Kernel xi: 132 d:  0 did not reach goal. check:  0.975882\n",
      "Kernel xi: 134 d:  0 did not reach goal. check:  1.717524\n",
      "Kernel xi: 136 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 138 d:  0 did not reach goal. check:  0.724250\n",
      "Kernel xi: 139 d:  0 did not reach goal. check:  1.301766\n",
      "Kernel xi: 144 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 145 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 146 d:  0 did not reach goal. check:  0.000260\n",
      "Kernel xi: 147 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 148 d:  0 did not reach goal. check:  1.301236\n",
      "Kernel xi: 149 d:  0 did not reach goal. check:  0.983497\n",
      "Kernel xi: 150 d:  0 did not reach goal. check:  1.973032\n",
      "Kernel xi: 151 d:  0 did not reach goal. check:  0.001093\n",
      "Kernel xi: 153 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 156 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 157 d:  0 did not reach goal. check:  0.646721\n",
      "Kernel xi: 161 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 162 d:  0 did not reach goal. check:  0.743423\n",
      "Kernel xi: 163 d:  0 did not reach goal. check:  11.011915\n",
      "Kernel xi: 164 d:  0 did not reach goal. check:  0.069419\n",
      "Kernel xi: 165 d:  0 did not reach goal. check:  0.813076\n",
      "Kernel xi: 167 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 172 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 173 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 174 d:  0 did not reach goal. check:  0.311634\n",
      "Kernel xi: 176 d:  0 did not reach goal. check:  0.135190\n",
      "Kernel xi: 178 d:  0 did not reach goal. check:  1.268633\n",
      "Kernel xi: 179 d:  0 did not reach goal. check:  4.459940\n",
      "Kernel xi: 180 d:  0 did not reach goal. check:  0.000012\n",
      "Kernel xi: 181 d:  0 did not reach goal. check:  0.975723\n",
      "Kernel xi: 182 d:  0 did not reach goal. check:  0.000002\n",
      "Kernel xi: 184 d:  0 did not reach goal. check:  0.000008\n",
      "Kernel xi: 185 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 186 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 187 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 188 d:  0 did not reach goal. check:  0.024764\n",
      "Kernel xi: 191 d:  0 did not reach goal. check:  0.342685\n",
      "Kernel xi: 4 d:  0 did not reach goal. check:  0.449709\n",
      "Kernel xi: 6 d:  0 did not reach goal. check:  0.145567\n",
      "Kernel xi: 9 d:  0 did not reach goal. check:  0.523307\n",
      "Kernel xi: 10 d:  0 did not reach goal. check:  0.000005\n",
      "Kernel xi: 11 d:  0 did not reach goal. check:  0.165496\n",
      "Kernel xi: 16 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 17 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 19 d:  0 did not reach goal. check:  0.002235\n",
      "Kernel xi: 23 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 27 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 31 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 32 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 33 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 34 d:  0 did not reach goal. check:  0.455939\n",
      "Kernel xi: 36 d:  0 did not reach goal. check:  0.054846\n",
      "Kernel xi: 37 d:  0 did not reach goal. check:  0.000025\n",
      "Kernel xi: 40 d:  0 did not reach goal. check:  0.826442\n",
      "Kernel xi: 41 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 43 d:  0 did not reach goal. check:  0.000445\n",
      "Kernel xi: 44 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 47 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 48 d:  0 did not reach goal. check:  0.822419\n",
      "Kernel xi: 49 d:  0 did not reach goal. check:  0.528083\n",
      "Kernel xi: 50 d:  0 did not reach goal. check:  0.000002\n",
      "Kernel xi: 51 d:  0 did not reach goal. check:  0.000171\n",
      "Kernel xi: 52 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 55 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 57 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 58 d:  0 did not reach goal. check:  0.000004\n",
      "Kernel xi: 59 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 63 d:  0 did not reach goal. check:  0.120931\n",
      "Kernel xi: 195 d:  0 did not reach goal. check:  0.000046\n",
      "Kernel xi: 196 d:  0 did not reach goal. check:  0.000001\n",
      "Kernel xi: 197 d:  0 did not reach goal. check:  0.676915\n",
      "Kernel xi: 198 d:  0 did not reach goal. check:  0.003335\n",
      "Kernel xi: 199 d:  0 did not reach goal. check:  0.000008\n",
      "Kernel xi: 200 d:  0 did not reach goal. check:  0.000009\n",
      "Kernel xi: 205 d:  0 did not reach goal. check:  10.478770\n",
      "Kernel xi: 206 d:  0 did not reach goal. check:  0.000106\n",
      "Kernel xi: 208 d:  0 did not reach goal. check:  1.007276\n",
      "Kernel xi: 209 d:  0 did not reach goal. check:  1.036129\n",
      "Kernel xi: 210 d:  0 did not reach goal. check:  0.649519\n",
      "Kernel xi: 211 d:  0 did not reach goal. check:  1.652606\n",
      "Kernel xi: 212 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 213 d:  0 did not reach goal. check:  2.511422\n",
      "Kernel xi: 214 d:  0 did not reach goal. check:  0.051453\n",
      "Kernel xi: 216 d:  0 did not reach goal. check:  0.335043\n",
      "Kernel xi: 217 d:  0 did not reach goal. check:  0.281178\n",
      "Kernel xi: 218 d:  0 did not reach goal. check:  0.000025\n",
      "Kernel xi: 221 d:  0 did not reach goal. check:  1.305091\n",
      "Kernel xi: 67 d:  0 did not reach goal. check:  0.009721\n",
      "Kernel xi: 69 d:  0 did not reach goal. check:  0.628958\n",
      "Kernel xi: 75 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 77 d:  0 did not reach goal. check:  0.000062\n",
      "Kernel xi: 78 d:  0 did not reach goal. check:  9.024766\n",
      "Kernel xi: 79 d:  0 did not reach goal. check:  0.000003\n",
      "Kernel xi: 80 d:  0 did not reach goal. check:  0.000007\n",
      "Kernel xi: 82 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 83 d:  0 did not reach goal. check:  0.000003\n",
      "Kernel xi: 84 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 85 d:  0 did not reach goal. check:  0.528322\n",
      "Kernel xi: 86 d:  0 did not reach goal. check:  0.528016\n",
      "Kernel xi: 87 d:  0 did not reach goal. check:  0.834889\n",
      "Kernel xi: 89 d:  0 did not reach goal. check:  0.721374\n",
      "Kernel xi: 90 d:  0 did not reach goal. check:  0.091205\n",
      "Kernel xi: 91 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 93 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 94 d:  0 did not reach goal. check:  0.000016\n",
      "Kernel xi: 225 d:  1 did not reach goal. check:  0.000002\n",
      "Kernel xi: 227 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 228 d:  1 did not reach goal. check:  1.966621\n",
      "Kernel xi: 229 d:  1 did not reach goal. check:  1.339215\n",
      "Kernel xi: 231 d:  1 did not reach goal. check:  0.201314\n",
      "Kernel xi: 233 d:  1 did not reach goal. check:  1.900491\n",
      "Kernel xi: 236 d:  1 did not reach goal. check:  1.689771\n",
      "Kernel xi: 238 d:  1 did not reach goal. check:  0.000002\n",
      "Kernel xi: 239 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 241 d:  1 did not reach goal. check:  0.052547\n",
      "Kernel xi: 243 d:  1 did not reach goal. check:  0.008839\n",
      "Kernel xi: 244 d:  1 did not reach goal. check:  0.143274\n",
      "Kernel xi: 245 d:  1 did not reach goal. check:  1.823749\n",
      "Kernel xi: 248 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 249 d:  1 did not reach goal. check:  0.228729\n",
      "Kernel xi: 251 d:  1 did not reach goal. check:  0.763699\n",
      "Kernel xi: 252 d:  1 did not reach goal. check:  1.191198\n",
      "Kernel xi: 253 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 96 d:  1 did not reach goal. check:  1.860477\n",
      "Kernel xi: 99 d:  1 did not reach goal. check:  2.826584\n",
      "Kernel xi: 102 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 104 d:  1 did not reach goal. check:  1.726008\n",
      "Kernel xi: 106 d:  1 did not reach goal. check:  0.011701\n",
      "Kernel xi: 107 d:  1 did not reach goal. check:  0.757558\n",
      "Kernel xi: 108 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 111 d:  1 did not reach goal. check:  4.014838\n",
      "Kernel xi: 112 d:  1 did not reach goal. check:  1.078618\n",
      "Kernel xi: 113 d:  1 did not reach goal. check:  1.571227\n",
      "Kernel xi: 115 d:  1 did not reach goal. check:  1.005080\n",
      "Kernel xi: 116 d:  1 did not reach goal. check:  0.252105\n",
      "Kernel xi: 117 d:  1 did not reach goal. check:  0.009218\n",
      "Kernel xi: 119 d:  1 did not reach goal. check:  0.626887\n",
      "Kernel xi: 121 d:  1 did not reach goal. check:  3.659958\n",
      "Kernel xi: 124 d:  1 did not reach goal. check:  1.679221\n",
      "Kernel xi: 127 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 162 d:  1 did not reach goal. check:  1.050057\n",
      "Kernel xi: 163 d:  1 did not reach goal. check:  0.000033\n",
      "Kernel xi: 164 d:  1 did not reach goal. check:  0.773726\n",
      "Kernel xi: 165 d:  1 did not reach goal. check:  0.612151\n",
      "Kernel xi: 167 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 169 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 171 d:  1 did not reach goal. check:  0.000003\n",
      "Kernel xi: 172 d:  1 did not reach goal. check:  1.231756\n",
      "Kernel xi: 173 d:  1 did not reach goal. check:  5.363698\n",
      "Kernel xi: 174 d:  1 did not reach goal. check:  1.627151\n",
      "Kernel xi: 177 d:  1 did not reach goal. check:  0.088070\n",
      "Kernel xi: 178 d:  1 did not reach goal. check:  0.038917\n",
      "Kernel xi: 179 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 180 d:  1 did not reach goal. check:  0.913877\n",
      "Kernel xi: 181 d:  1 did not reach goal. check:  1.809696\n",
      "Kernel xi: 184 d:  1 did not reach goal. check:  0.021159\n",
      "Kernel xi: 187 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 188 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 190 d:  1 did not reach goal. check:  7.865646\n",
      "Kernel xi: 33 d:  1 did not reach goal. check:  0.551401\n",
      "Kernel xi: 34 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 35 d:  1 did not reach goal. check:  0.000806\n",
      "Kernel xi: 36 d:  1 did not reach goal. check:  0.349181\n",
      "Kernel xi: 37 d:  1 did not reach goal. check:  0.029076\n",
      "Kernel xi: 41 d:  1 did not reach goal. check:  0.472881\n",
      "Kernel xi: 42 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 44 d:  1 did not reach goal. check:  0.849322\n",
      "Kernel xi: 45 d:  1 did not reach goal. check:  0.358237\n",
      "Kernel xi: 47 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 48 d:  1 did not reach goal. check:  2.192179\n",
      "Kernel xi: 49 d:  1 did not reach goal. check:  0.888879\n",
      "Kernel xi: 50 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 52 d:  1 did not reach goal. check:  1.132542\n",
      "Kernel xi: 53 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 55 d:  1 did not reach goal. check:  0.779971\n",
      "Kernel xi: 56 d:  1 did not reach goal. check:  0.552087\n",
      "Kernel xi: 58 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 61 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 63 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 128 d:  1 did not reach goal. check:  0.218880\n",
      "Kernel xi: 130 d:  1 did not reach goal. check:  1.203156\n",
      "Kernel xi: 132 d:  1 did not reach goal. check:  0.200517\n",
      "Kernel xi: 133 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 134 d:  1 did not reach goal. check:  0.190823\n",
      "Kernel xi: 138 d:  1 did not reach goal. check:  2.372353\n",
      "Kernel xi: 142 d:  1 did not reach goal. check:  0.118658\n",
      "Kernel xi: 143 d:  1 did not reach goal. check:  0.992803\n",
      "Kernel xi: 144 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 146 d:  1 did not reach goal. check:  1.776456\n",
      "Kernel xi: 148 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 150 d:  1 did not reach goal. check:  0.000004\n",
      "Kernel xi: 151 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 153 d:  1 did not reach goal. check:  0.931163\n",
      "Kernel xi: 157 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 158 d:  1 did not reach goal. check:  5.539609\n",
      "Kernel xi: 159 d:  1 did not reach goal. check:  2.227703\n",
      "Kernel xi: 0 d:  1 did not reach goal. check:  0.414268\n",
      "Kernel xi: 3 d:  1 did not reach goal. check:  0.857199\n",
      "Kernel xi: 4 d:  1 did not reach goal. check:  0.694233\n",
      "Kernel xi: 5 d:  1 did not reach goal. check:  0.448643\n",
      "Kernel xi: 6 d:  1 did not reach goal. check:  0.331731\n",
      "Kernel xi: 9 d:  1 did not reach goal. check:  0.170954\n",
      "Kernel xi: 10 d:  1 did not reach goal. check:  0.000016\n",
      "Kernel xi: 11 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 12 d:  1 did not reach goal. check:  0.050873\n",
      "Kernel xi: 13 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 14 d:  1 did not reach goal. check:  0.005000\n",
      "Kernel xi: 15 d:  1 did not reach goal. check:  0.771422\n",
      "Kernel xi: 17 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 19 d:  1 did not reach goal. check:  0.792084\n",
      "Kernel xi: 22 d:  1 did not reach goal. check:  1.293783\n",
      "Kernel xi: 23 d:  1 did not reach goal. check:  0.735768\n",
      "Kernel xi: 24 d:  1 did not reach goal. check:  0.006554\n",
      "Kernel xi: 26 d:  1 did not reach goal. check:  0.400761\n",
      "Kernel xi: 28 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 30 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 31 d:  1 did not reach goal. check:  4.784503\n",
      "Kernel xi: 193 d:  1 did not reach goal. check:  1.412384\n",
      "Kernel xi: 194 d:  1 did not reach goal. check:  1.536482\n",
      "Kernel xi: 195 d:  1 did not reach goal. check:  1.460407\n",
      "Kernel xi: 196 d:  1 did not reach goal. check:  2.488043\n",
      "Kernel xi: 197 d:  1 did not reach goal. check:  1.576867\n",
      "Kernel xi: 199 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 200 d:  1 did not reach goal. check:  0.799974\n",
      "Kernel xi: 203 d:  1 did not reach goal. check:  0.616349\n",
      "Kernel xi: 204 d:  1 did not reach goal. check:  0.503925\n",
      "Kernel xi: 205 d:  1 did not reach goal. check:  2.253731\n",
      "Kernel xi: 206 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 209 d:  1 did not reach goal. check:  1.619793\n",
      "Kernel xi: 211 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 212 d:  1 did not reach goal. check:  0.000016\n",
      "Kernel xi: 213 d:  1 did not reach goal. check:  2.118870\n",
      "Kernel xi: 216 d:  1 did not reach goal. check:  2.667753\n",
      "Kernel xi: 217 d:  1 did not reach goal. check:  0.002391\n",
      "Kernel xi: 218 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 219 d:  1 did not reach goal. check:  0.000404\n",
      "Kernel xi: 221 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 223 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 64 d:  1 did not reach goal. check:  6.517440\n",
      "Kernel xi: 66 d:  1 did not reach goal. check:  0.015945\n",
      "Kernel xi: 68 d:  1 did not reach goal. check:  1.221196\n",
      "Kernel xi: 70 d:  1 did not reach goal. check:  0.491901\n",
      "Kernel xi: 71 d:  1 did not reach goal. check:  0.883082\n",
      "Kernel xi: 72 d:  1 did not reach goal. check:  1.047449\n",
      "Kernel xi: 73 d:  1 did not reach goal. check:  1.367522\n",
      "Kernel xi: 74 d:  1 did not reach goal. check:  2.463671\n",
      "Kernel xi: 75 d:  1 did not reach goal. check:  1.613763\n",
      "Kernel xi: 79 d:  1 did not reach goal. check:  0.000050\n",
      "Kernel xi: 80 d:  1 did not reach goal. check:  1.037792\n",
      "Kernel xi: 83 d:  1 did not reach goal. check:  0.093371\n",
      "Kernel xi: 86 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 87 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 88 d:  1 did not reach goal. check:  0.520160\n",
      "Kernel xi: 89 d:  1 did not reach goal. check:  0.000920\n",
      "Kernel xi: 90 d:  1 did not reach goal. check:  3.256473\n",
      "Kernel xi: 91 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 95 d:  1 did not reach goal. check:  0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "  3%|▎         | 1/32 [00:01<00:53,  1.72s/it]/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home2/carlos.lamas/condacurraun/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "100%|██████████| 32/32 [00:01<00:00, 17.89it/s]\n"
     ]
    }
   ],
   "source": [
    "output = simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplus_lc = output[\"uplus_lc\"]\n",
    "nplus = output[\"nplus\"]\n",
    "\n",
    "#TODO: remove after debug\n",
    "# uplus_temp = output[\"uplus_temp\"]\n",
    "\n",
    "if lc_gauge.LCDEBUG:\n",
    "    uminus_lc = output[\"uminus_lc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 16, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uplus_lc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x3000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "y = 0\n",
    "\n",
    "fig_um, axs_um = plt.subplots(1, 3, figsize=(15,30))\n",
    "\n",
    "for ixplus in range(nplus//3 + 1): \n",
    "    xplus = ixplus * 2 + 1\n",
    "    \n",
    "    uminuc_lc_color = uminus_lc[xplus, y, :].real.reshape(3,3)\n",
    "    axs_um[ixplus].imshow(uminuc_lc_color, cmap='turbo', vmin=0, vmax=1) \n",
    "    axs_um[ixplus].set_title(r'$U_-^{LC}(x^+ = %i $)' %xplus)\n",
    "    # plt.colorbar(plot1, ax = axs[t,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x3000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_up, axs_up = plt.subplots(1, 3, figsize=(15,30))\n",
    "\n",
    "for ixplus in range(nplus//3 + 1): \n",
    "    xplus = ixplus * 2 + 1\n",
    "    \n",
    "    uplus_lc_color = uplus_lc[xplus, y, :].real.reshape(3,3)\n",
    "    axs_up[ixplus].imshow(uplus_lc_color, cmap='turbo', vmin=0, vmax=1) \n",
    "    axs_up[ixplus].set_title(r'$U_+^{LC}(x^+ = %i $)' %xplus)\n",
    "    # plt.colorbar(plot1, ax = axs[t,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "### Comparison with the CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MY_NUMBA_TARGET\"] = \"numba\"\n",
    "os.environ[\"PRECISION\"] = \"double\"\n",
    "os.environ['GAUGE_GROUP'] = su_group\n",
    "\n",
    "# Import relevant modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Glasma modules\n",
    "import curraun.core as core\n",
    "import curraun.mv as mv\n",
    "import curraun.initial as initial\n",
    "initial.DEBUG = False\n",
    "\n",
    "# Don't print accuracy check \n",
    "import curraun.initial_su3 as initial_su3\n",
    "initial_su3.DEBUG = False\n",
    "\n",
    "import curraun.su as su\n",
    "from curraun.numba_target import use_cuda\n",
    "if use_cuda:\n",
    "    from numba import cuda\n",
    "\n",
    "import curraun.su as su\n",
    "import curraun.lc_gauge_zindep as lc_gauge\n",
    "\n",
    "# Number of colors\n",
    "Nc = su.NC\n",
    "# Dimension of algebra \n",
    "Dg = su.GROUP_ELEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress various horribly long warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Simulation routine\n",
    "def simulate(): \n",
    "    output = {}\n",
    "    # Derived parameters\n",
    "    a = L / N\n",
    "    E0 = N / L * hbarc\n",
    "    DT = 1.0 / DTS\n",
    "    maxt = int(tau_sim / a * DTS)\n",
    "\n",
    "    #TODO: for testing only, remove after testing\n",
    "    mv.set_seed(24)\n",
    "\n",
    "    # Initialize Glasma fields\n",
    "    s = core.Simulation(N, DT, g)\n",
    "\n",
    "    va = mv.wilson(s, mu=mu / E0, m=ir / E0, uv=uv / E0, num_sheets=ns)\n",
    "    vb = mv.wilson(s, mu=mu / E0, m=ir / E0, uv=uv / E0, num_sheets=ns)\n",
    "    initial.init(s, va, vb)\n",
    "\n",
    "    nplus = maxt//DTS\n",
    "\n",
    "    # Plus gauge link\n",
    "    uplus_lc = su.GROUP_TYPE(np.zeros((maxt//DTS-1, N, Dg)))\n",
    "    vlc = su.GROUP_TYPE([[su.unit() for y in range(N)] for xplus in range (maxt//DTS)])\n",
    "    # vlc_out = su.GROUP_TYPE(np.zeros((nplus, nplus, N, su.GROUP_ELEMENTS)))\n",
    "    uplus_temp = su.GROUP_TYPE(np.zeros((maxt//DTS-1, N, Dg)))\n",
    "\n",
    "    with tqdm(total=maxt) as pbar:\n",
    "        for t in range(maxt):            \n",
    "            # Evolve Glasma fields\n",
    "            core.evolve_leapfrog(s)\n",
    "\n",
    "            if t%DTS == 0:\n",
    "                xplus = t//DTS\n",
    "                \n",
    "                u1 = s.u1.copy()\n",
    "                u0 = s.u0.copy()\n",
    "                \n",
    "                ux_act = u1[:,0,:].reshape(N,N,Dg)\n",
    "                ux_prev = u0[:,0,:].reshape(N,N,Dg)\n",
    "   \n",
    "                # We construct the u_+ links over the x^+ axis in a y transverse lattice\n",
    "                up_temp_test = su.GROUP_TYPE(np.zeros((N,Dg)))\n",
    "                \n",
    "                for ix in range(maxt//DTS):\n",
    "                    for y in range(N):\n",
    "                        if ix > (t//DTS): # We construct the gauge operator\n",
    "                            v_prev = vlc[ix, y]\n",
    "                            vlc[ix, y] = lc_gauge.gauge_transformation_operator(ux_act[2*ix-t//DTS,y], v_prev) \n",
    "                            \n",
    "                        elif ix == (t//DTS) and ix != 0:\n",
    "                            up_temp_test[y] = lc_gauge.get_plus_links(ux_prev[t//DTS,y])\n",
    "                            uplus_temp[t//DTS-1, y] = up_temp_test[y]            \n",
    "\n",
    "                            uplus_lc[xplus-1, y, :] = lc_gauge.act_on_links(up_temp_test[y], vlc[ix, y], vlc[ix-1, y])\n",
    "\n",
    "                # vlc_out[xplus] = vlc\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    if use_cuda:\n",
    "        cuda.current_context().deallocations.clear()\n",
    "\n",
    "    output[\"nplus\"] = nplus\n",
    "\n",
    "    output[\"uplus_lc\"] = uplus_lc\n",
    "    output[\"uplus_temp\"] = uplus_temp \n",
    "    # output[\"vlc\"] = vlc \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel xi: 195 d:  0 did not reach goal. check:  0.000046\n",
      "Kernel xi: 196 d:  0 did not reach goal. check:  0.000001\n",
      "Kernel xi: 197 d:  0 did not reach goal. check:  0.676915\n",
      "Kernel xi: 198 d:  0 did not reach goal. check:  0.003335\n",
      "Kernel xi: 199 d:  0 did not reach goal. check:  0.000008\n",
      "Kernel xi: 200 d:  0 did not reach goal. check:  0.000009\n",
      "Kernel xi: 205 d:  0 did not reach goal. check:  10.478770\n",
      "Kernel xi: 206 d:  0 did not reach goal. check:  0.000106\n",
      "Kernel xi: 208 d:  0 did not reach goal. check:  1.007276\n",
      "Kernel xi: 209 d:  0 did not reach goal. check:  1.036129\n",
      "Kernel xi: 210 d:  0 did not reach goal. check:  0.649519\n",
      "Kernel xi: 211 d:  0 did not reach goal. check:  1.652606\n",
      "Kernel xi: 212 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 213 d:  0 did not reach goal. check:  2.511422\n",
      "Kernel xi: 214 d:  0 did not reach goal. check:  0.051453\n",
      "Kernel xi: 216 d:  0 did not reach goal. check:  0.335043\n",
      "Kernel xi: 217 d:  0 did not reach goal. check:  0.281178\n",
      "Kernel xi: 218 d:  0 did not reach goal. check:  0.000025\n",
      "Kernel xi: 221 d:  0 did not reach goal. check:  1.305091\n",
      "Kernel xi: 228 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 231 d:  0 did not reach goal. check:  0.000983\n",
      "Kernel xi: 232 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 233 d:  0 did not reach goal. check:  0.934217\n",
      "Kernel xi: 234 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 236 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 237 d:  0 did not reach goal. check:  0.843181\n",
      "Kernel xi: 238 d:  0 did not reach goal. check:  2.358576\n",
      "Kernel xi: 241 d:  0 did not reach goal. check:  1.157817\n",
      "Kernel xi: 242 d:  0 did not reach goal. check:  1.086507\n",
      "Kernel xi: 243 d:  0 did not reach goal. check:  1.773258\n",
      "Kernel xi: 247 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 248 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 249 d:  0 did not reach goal. check:  0.096570\n",
      "Kernel xi: 253 d:  0 did not reach goal. check:  0.636997\n",
      "Kernel xi: 254 d:  0 did not reach goal. check:  0.416994\n",
      "Kernel xi: 255 d:  0 did not reach goal. check:  0.533396\n",
      "Kernel xi: 67 d:  0 did not reach goal. check:  0.009721\n",
      "Kernel xi: 69 d:  0 did not reach goal. check:  0.628958\n",
      "Kernel xi: 75 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 77 d:  0 did not reach goal. check:  0.000062\n",
      "Kernel xi: 78 d:  0 did not reach goal. check:  9.024766\n",
      "Kernel xi: 79 d:  0 did not reach goal. check:  0.000003\n",
      "Kernel xi: 80 d:  0 did not reach goal. check:  0.000007\n",
      "Kernel xi: 82 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 83 d:  0 did not reach goal. check:  0.000003\n",
      "Kernel xi: 84 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 85 d:  0 did not reach goal. check:  0.528322\n",
      "Kernel xi: 86 d:  0 did not reach goal. check:  0.528016\n",
      "Kernel xi: 87 d:  0 did not reach goal. check:  0.834889\n",
      "Kernel xi: 89 d:  0 did not reach goal. check:  0.721374\n",
      "Kernel xi: 90 d:  0 did not reach goal. check:  0.091205\n",
      "Kernel xi: 91 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 93 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 94 d:  0 did not reach goal. check:  0.000016\n",
      "Kernel xi: 96 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 97 d:  0 did not reach goal. check:  1.178754\n",
      "Kernel xi: 101 d:  0 did not reach goal. check:  2.963470\n",
      "Kernel xi: 103 d:  0 did not reach goal. check:  0.018364\n",
      "Kernel xi: 104 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 107 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 108 d:  0 did not reach goal. check:  0.322777\n",
      "Kernel xi: 109 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 110 d:  0 did not reach goal. check:  0.000668\n",
      "Kernel xi: 112 d:  0 did not reach goal. check:  1.246753\n",
      "Kernel xi: 114 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 115 d:  0 did not reach goal. check:  0.708489\n",
      "Kernel xi: 118 d:  0 did not reach goal. check:  0.052575\n",
      "Kernel xi: 119 d:  0 did not reach goal. check:  0.146152\n",
      "Kernel xi: 122 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 123 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 124 d:  0 did not reach goal. check:  0.019707\n",
      "Kernel xi: 125 d:  0 did not reach goal. check:  0.094324\n",
      "Kernel xi: 128 d:  0 did not reach goal. check:  0.000113\n",
      "Kernel xi: 129 d:  0 did not reach goal. check:  0.133841\n",
      "Kernel xi: 130 d:  0 did not reach goal. check:  0.000768\n",
      "Kernel xi: 131 d:  0 did not reach goal. check:  0.009965\n",
      "Kernel xi: 132 d:  0 did not reach goal. check:  0.975882\n",
      "Kernel xi: 134 d:  0 did not reach goal. check:  1.717524\n",
      "Kernel xi: 136 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 138 d:  0 did not reach goal. check:  0.724250\n",
      "Kernel xi: 139 d:  0 did not reach goal. check:  1.301766\n",
      "Kernel xi: 144 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 145 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 146 d:  0 did not reach goal. check:  0.000260\n",
      "Kernel xi: 147 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 148 d:  0 did not reach goal. check:  1.301236\n",
      "Kernel xi: 149 d:  0 did not reach goal. check:  0.983497\n",
      "Kernel xi: 150 d:  0 did not reach goal. check:  1.973032\n",
      "Kernel xi: 151 d:  0 did not reach goal. check:  0.001093\n",
      "Kernel xi: 153 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 156 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 157 d:  0 did not reach goal. check:  0.646721\n",
      "Kernel xi: 4 d:  0 did not reach goal. check:  0.449709\n",
      "Kernel xi: 6 d:  0 did not reach goal. check:  0.145567\n",
      "Kernel xi: 9 d:  0 did not reach goal. check:  0.523307\n",
      "Kernel xi: 10 d:  0 did not reach goal. check:  0.000005\n",
      "Kernel xi: 11 d:  0 did not reach goal. check:  0.165496\n",
      "Kernel xi: 16 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 17 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 19 d:  0 did not reach goal. check:  0.002235\n",
      "Kernel xi: 23 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 27 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 31 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 161 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 162 d:  0 did not reach goal. check:  0.743423\n",
      "Kernel xi: 163 d:  0 did not reach goal. check:  11.011915\n",
      "Kernel xi: 164 d:  0 did not reach goal. check:  0.069419\n",
      "Kernel xi: 165 d:  0 did not reach goal. check:  0.813076\n",
      "Kernel xi: 167 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 172 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 173 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 174 d:  0 did not reach goal. check:  0.311634\n",
      "Kernel xi: 176 d:  0 did not reach goal. check:  0.135190\n",
      "Kernel xi: 178 d:  0 did not reach goal. check:  1.268633\n",
      "Kernel xi: 179 d:  0 did not reach goal. check:  4.459940\n",
      "Kernel xi: 180 d:  0 did not reach goal. check:  0.000012\n",
      "Kernel xi: 181 d:  0 did not reach goal. check:  0.975723\n",
      "Kernel xi: 182 d:  0 did not reach goal. check:  0.000002\n",
      "Kernel xi: 184 d:  0 did not reach goal. check:  0.000008\n",
      "Kernel xi: 185 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 186 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 187 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 188 d:  0 did not reach goal. check:  0.024764\n",
      "Kernel xi: 191 d:  0 did not reach goal. check:  0.342685\n",
      "Kernel xi: 32 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 33 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 34 d:  0 did not reach goal. check:  0.455939\n",
      "Kernel xi: 36 d:  0 did not reach goal. check:  0.054846\n",
      "Kernel xi: 37 d:  0 did not reach goal. check:  0.000025\n",
      "Kernel xi: 40 d:  0 did not reach goal. check:  0.826442\n",
      "Kernel xi: 41 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 43 d:  0 did not reach goal. check:  0.000445\n",
      "Kernel xi: 44 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 47 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 48 d:  0 did not reach goal. check:  0.822419\n",
      "Kernel xi: 49 d:  0 did not reach goal. check:  0.528083\n",
      "Kernel xi: 50 d:  0 did not reach goal. check:  0.000002\n",
      "Kernel xi: 51 d:  0 did not reach goal. check:  0.000171\n",
      "Kernel xi: 52 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 55 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 57 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 58 d:  0 did not reach goal. check:  0.000004\n",
      "Kernel xi: 59 d:  0 did not reach goal. check:  0.000000\n",
      "Kernel xi: 63 d:  0 did not reach goal. check:  0.120931\n",
      "Kernel xi: 225 d:  1 did not reach goal. check:  0.000002\n",
      "Kernel xi: 227 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 228 d:  1 did not reach goal. check:  1.966621\n",
      "Kernel xi: 229 d:  1 did not reach goal. check:  1.339215\n",
      "Kernel xi: 231 d:  1 did not reach goal. check:  0.201314\n",
      "Kernel xi: 233 d:  1 did not reach goal. check:  1.900491\n",
      "Kernel xi: 236 d:  1 did not reach goal. check:  1.689771\n",
      "Kernel xi: 238 d:  1 did not reach goal. check:  0.000002\n",
      "Kernel xi: 239 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 241 d:  1 did not reach goal. check:  0.052547\n",
      "Kernel xi: 243 d:  1 did not reach goal. check:  0.008839\n",
      "Kernel xi: 244 d:  1 did not reach goal. check:  0.143274\n",
      "Kernel xi: 245 d:  1 did not reach goal. check:  1.823749\n",
      "Kernel xi: 248 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 249 d:  1 did not reach goal. check:  0.228729\n",
      "Kernel xi: 251 d:  1 did not reach goal. check:  0.763699\n",
      "Kernel xi: 252 d:  1 did not reach goal. check:  1.191198\n",
      "Kernel xi: 253 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 193 d:  1 did not reach goal. check:  1.412384\n",
      "Kernel xi: 194 d:  1 did not reach goal. check:  1.536482\n",
      "Kernel xi: 195 d:  1 did not reach goal. check:  1.460407\n",
      "Kernel xi: 196 d:  1 did not reach goal. check:  2.488043\n",
      "Kernel xi: 197 d:  1 did not reach goal. check:  1.576867\n",
      "Kernel xi: 199 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 200 d:  1 did not reach goal. check:  0.799974\n",
      "Kernel xi: 203 d:  1 did not reach goal. check:  0.616349\n",
      "Kernel xi: 204 d:  1 did not reach goal. check:  0.503925\n",
      "Kernel xi: 205 d:  1 did not reach goal. check:  2.253731\n",
      "Kernel xi: 206 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 209 d:  1 did not reach goal. check:  1.619793\n",
      "Kernel xi: 211 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 212 d:  1 did not reach goal. check:  0.000016\n",
      "Kernel xi: 213 d:  1 did not reach goal. check:  2.118870\n",
      "Kernel xi: 216 d:  1 did not reach goal. check:  2.667753\n",
      "Kernel xi: 217 d:  1 did not reach goal. check:  0.002391\n",
      "Kernel xi: 218 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 219 d:  1 did not reach goal. check:  0.000404\n",
      "Kernel xi: 221 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 223 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 162 d:  1 did not reach goal. check:  1.050057\n",
      "Kernel xi: 163 d:  1 did not reach goal. check:  0.000033\n",
      "Kernel xi: 164 d:  1 did not reach goal. check:  0.773726\n",
      "Kernel xi: 165 d:  1 did not reach goal. check:  0.612151\n",
      "Kernel xi: 167 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 169 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 171 d:  1 did not reach goal. check:  0.000003\n",
      "Kernel xi: 172 d:  1 did not reach goal. check:  1.231756\n",
      "Kernel xi: 173 d:  1 did not reach goal. check:  5.363698\n",
      "Kernel xi: 174 d:  1 did not reach goal. check:  1.627151\n",
      "Kernel xi: 177 d:  1 did not reach goal. check:  0.088070\n",
      "Kernel xi: 178 d:  1 did not reach goal. check:  0.038917\n",
      "Kernel xi: 179 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 180 d:  1 did not reach goal. check:  0.913877\n",
      "Kernel xi: 181 d:  1 did not reach goal. check:  1.809696\n",
      "Kernel xi: 184 d:  1 did not reach goal. check:  0.021159\n",
      "Kernel xi: 187 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 188 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 190 d:  1 did not reach goal. check:  7.865646\n",
      "Kernel xi: 33 d:  1 did not reach goal. check:  0.551401\n",
      "Kernel xi: 34 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 35 d:  1 did not reach goal. check:  0.000806\n",
      "Kernel xi: 36 d:  1 did not reach goal. check:  0.349181\n",
      "Kernel xi: 37 d:  1 did not reach goal. check:  0.029076\n",
      "Kernel xi: 41 d:  1 did not reach goal. check:  0.472881\n",
      "Kernel xi: 42 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 44 d:  1 did not reach goal. check:  0.849322\n",
      "Kernel xi: 45 d:  1 did not reach goal. check:  0.358237\n",
      "Kernel xi: 47 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 48 d:  1 did not reach goal. check:  2.192179\n",
      "Kernel xi: 49 d:  1 did not reach goal. check:  0.888879\n",
      "Kernel xi: 50 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 52 d:  1 did not reach goal. check:  1.132542\n",
      "Kernel xi: 53 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 55 d:  1 did not reach goal. check:  0.779971\n",
      "Kernel xi: 56 d:  1 did not reach goal. check:  0.552087\n",
      "Kernel xi: 58 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 61 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 63 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 96 d:  1 did not reach goal. check:  1.860477\n",
      "Kernel xi: 99 d:  1 did not reach goal. check:  2.826584\n",
      "Kernel xi: 102 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 104 d:  1 did not reach goal. check:  1.726008\n",
      "Kernel xi: 106 d:  1 did not reach goal. check:  0.011701\n",
      "Kernel xi: 107 d:  1 did not reach goal. check:  0.757558\n",
      "Kernel xi: 108 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 111 d:  1 did not reach goal. check:  4.014838\n",
      "Kernel xi: 112 d:  1 did not reach goal. check:  1.078618\n",
      "Kernel xi: 113 d:  1 did not reach goal. check:  1.571227\n",
      "Kernel xi: 115 d:  1 did not reach goal. check:  1.005080\n",
      "Kernel xi: 116 d:  1 did not reach goal. check:  0.252105\n",
      "Kernel xi: 117 d:  1 did not reach goal. check:  0.009218\n",
      "Kernel xi: 119 d:  1 did not reach goal. check:  0.626887\n",
      "Kernel xi: 121 d:  1 did not reach goal. check:  3.659958\n",
      "Kernel xi: 124 d:  1 did not reach goal. check:  1.679221\n",
      "Kernel xi: 127 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 64 d:  1 did not reach goal. check:  6.517440\n",
      "Kernel xi: 66 d:  1 did not reach goal. check:  0.015945\n",
      "Kernel xi: 68 d:  1 did not reach goal. check:  1.221196\n",
      "Kernel xi: 70 d:  1 did not reach goal. check:  0.491901\n",
      "Kernel xi: 71 d:  1 did not reach goal. check:  0.883082\n",
      "Kernel xi: 72 d:  1 did not reach goal. check:  1.047449\n",
      "Kernel xi: 73 d:  1 did not reach goal. check:  1.367522\n",
      "Kernel xi: 74 d:  1 did not reach goal. check:  2.463671\n",
      "Kernel xi: 75 d:  1 did not reach goal. check:  1.613763\n",
      "Kernel xi: 79 d:  1 did not reach goal. check:  0.000050\n",
      "Kernel xi: 80 d:  1 did not reach goal. check:  1.037792\n",
      "Kernel xi: 83 d:  1 did not reach goal. check:  0.093371\n",
      "Kernel xi: 86 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 87 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 88 d:  1 did not reach goal. check:  0.520160\n",
      "Kernel xi: 89 d:  1 did not reach goal. check:  0.000920\n",
      "Kernel xi: 90 d:  1 did not reach goal. check:  3.256473\n",
      "Kernel xi: 91 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 95 d:  1 did not reach goal. check:  0.000004\n",
      "Kernel xi: 128 d:  1 did not reach goal. check:  0.218880\n",
      "Kernel xi: 130 d:  1 did not reach goal. check:  1.203156\n",
      "Kernel xi: 132 d:  1 did not reach goal. check:  0.200517\n",
      "Kernel xi: 133 d:  1 did not reach goal. check:  0.000001\n",
      "Kernel xi: 134 d:  1 did not reach goal. check:  0.190823\n",
      "Kernel xi: 138 d:  1 did not reach goal. check:  2.372353\n",
      "Kernel xi: 142 d:  1 did not reach goal. check:  0.118658\n",
      "Kernel xi: 143 d:  1 did not reach goal. check:  0.992803\n",
      "Kernel xi: 144 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 146 d:  1 did not reach goal. check:  1.776456\n",
      "Kernel xi: 148 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 150 d:  1 did not reach goal. check:  0.000004\n",
      "Kernel xi: 151 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 153 d:  1 did not reach goal. check:  0.931163\n",
      "Kernel xi: 157 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 158 d:  1 did not reach goal. check:  5.539609\n",
      "Kernel xi: 159 d:  1 did not reach goal. check:  2.227703\n",
      "Kernel xi: 0 d:  1 did not reach goal. check:  0.414268\n",
      "Kernel xi: 3 d:  1 did not reach goal. check:  0.857199\n",
      "Kernel xi: 4 d:  1 did not reach goal. check:  0.694233\n",
      "Kernel xi: 5 d:  1 did not reach goal. check:  0.448643\n",
      "Kernel xi: 6 d:  1 did not reach goal. check:  0.331731\n",
      "Kernel xi: 9 d:  1 did not reach goal. check:  0.170954\n",
      "Kernel xi: 10 d:  1 did not reach goal. check:  0.000016\n",
      "Kernel xi: 11 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 12 d:  1 did not reach goal. check:  0.050873\n",
      "Kernel xi: 13 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 14 d:  1 did not reach goal. check:  0.005000\n",
      "Kernel xi: 15 d:  1 did not reach goal. check:  0.771422\n",
      "Kernel xi: 17 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 19 d:  1 did not reach goal. check:  0.792084\n",
      "Kernel xi: 22 d:  1 did not reach goal. check:  1.293783\n",
      "Kernel xi: 23 d:  1 did not reach goal. check:  0.735768\n",
      "Kernel xi: 24 d:  1 did not reach goal. check:  0.006554\n",
      "Kernel xi: 26 d:  1 did not reach goal. check:  0.400761\n",
      "Kernel xi: 28 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 30 d:  1 did not reach goal. check:  0.000000\n",
      "Kernel xi: 31 d:  1 did not reach goal. check:  4.784503\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nKernel launch configuration was not specified. Use the syntax:\n\nkernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n\nSee https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Plus gauge link\u001b[39;00m\n\u001b[1;32m     26\u001b[0m uplus_lc \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mGROUP_TYPE(np\u001b[38;5;241m.\u001b[39mzeros((maxt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mDTS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, N, Dg)))\n\u001b[0;32m---> 27\u001b[0m vlc \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mGROUP_TYPE([[su\u001b[38;5;241m.\u001b[39munit() \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N)] \u001b[38;5;28;01mfor\u001b[39;00m xplus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (maxt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mDTS)])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# vlc_out = su.GROUP_TYPE(np.zeros((nplus, nplus, N, su.GROUP_ELEMENTS)))\u001b[39;00m\n\u001b[1;32m     29\u001b[0m uplus_temp \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mGROUP_TYPE(np\u001b[38;5;241m.\u001b[39mzeros((maxt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mDTS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, N, Dg)))\n",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Plus gauge link\u001b[39;00m\n\u001b[1;32m     26\u001b[0m uplus_lc \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mGROUP_TYPE(np\u001b[38;5;241m.\u001b[39mzeros((maxt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mDTS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, N, Dg)))\n\u001b[0;32m---> 27\u001b[0m vlc \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mGROUP_TYPE([[su\u001b[38;5;241m.\u001b[39munit() \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N)] \u001b[38;5;28;01mfor\u001b[39;00m xplus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (maxt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mDTS)])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# vlc_out = su.GROUP_TYPE(np.zeros((nplus, nplus, N, su.GROUP_ELEMENTS)))\u001b[39;00m\n\u001b[1;32m     29\u001b[0m uplus_temp \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mGROUP_TYPE(np\u001b[38;5;241m.\u001b[39mzeros((maxt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mDTS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, N, Dg)))\n",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Plus gauge link\u001b[39;00m\n\u001b[1;32m     26\u001b[0m uplus_lc \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mGROUP_TYPE(np\u001b[38;5;241m.\u001b[39mzeros((maxt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mDTS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, N, Dg)))\n\u001b[0;32m---> 27\u001b[0m vlc \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mGROUP_TYPE([[\u001b[43msu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N)] \u001b[38;5;28;01mfor\u001b[39;00m xplus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (maxt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mDTS)])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# vlc_out = su.GROUP_TYPE(np.zeros((nplus, nplus, N, su.GROUP_ELEMENTS)))\u001b[39;00m\n\u001b[1;32m     29\u001b[0m uplus_temp \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mGROUP_TYPE(np\u001b[38;5;241m.\u001b[39mzeros((maxt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mDTS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, N, Dg)))\n",
      "File \u001b[0;32m~/condacurraun/lib/python3.10/site-packages/numba/cuda/compiler.py:908\u001b[0m, in \u001b[0;36mDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# An attempt to launch an unconfigured kernel\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(missing_launch_config_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: \nKernel launch configuration was not specified. Use the syntax:\n\nkernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n\nSee https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n\n"
     ]
    }
   ],
   "source": [
    "output = simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplus_lc = output[\"uplus_lc\"]\n",
    "nplus = output[\"nplus\"]\n",
    "\n",
    "#TODO: remove after debug\n",
    "# uplus_temp = output[\"uplus_temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x2160 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "y = 0\n",
    "nplus = uplus_lc.shape[0]\n",
    "\n",
    "fig_up, axs_up = plt.subplots(1, 3, figsize=(15,30))\n",
    "\n",
    "for ixplus in range(nplus//3 + 1): \n",
    "    xplus = ixplus * 2 + 1\n",
    "    \n",
    "    uplus_lc_color = uplus_lc[xplus, y, :].real.reshape(3,3)\n",
    "    axs_up[ixplus].imshow(uplus_lc_color, cmap='turbo', vmin=0, vmax=1) \n",
    "    axs_up[ixplus].set_title(r'$U_+^{LC}(x^+ = %i $)' %xplus)\n",
    "    # plt.colorbar(plot1, ax = axs[t,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Test lattice functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ny, Nxplus = N, N//2\n",
    "# Test arrray\n",
    "test = np.zeros(Ny*Nxplus)\n",
    "for i in range(Ny-1):\n",
    "    for j in range(Nxplus-1):\n",
    "        test[i*Nxplus+j] = i*Nxplus+j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_nm(ix, iy, n):\n",
    "    return n * ix + iy\n",
    "def get_point_nxm(x, n, m):\n",
    "    r1 = x % m \n",
    "    r0 = (x - r1) // m\n",
    "    return r0, r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = get_index_nm(12, 3, Ny)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nxplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_point_nxm(index, Nxplus, Ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Debug\n",
    "Run both the CPU and GPU codes using `numba` in the same loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# hbar * c [GeV * fm]\n",
    "hbarc = 0.197326 \n",
    "\n",
    "# Simulation box \n",
    "L = 2      \n",
    "# N = 128   \n",
    "N = 16 \n",
    "tau_sim = 1     \n",
    "DTS = 4     \n",
    "\n",
    "# Glasma fields\n",
    "su_group = 'su3'\n",
    "Qs = 2        \n",
    "ns = 50    \n",
    "factor = 0.8        \n",
    "g2mu = Qs / factor     \n",
    "g = np.pi * np.sqrt(1 / np.log(Qs / 0.2))          \t\t\n",
    "mu = g2mu / g**2          \t\n",
    "ir = 0.1 * g**2 * mu         \n",
    "uv = 10.0       \n",
    "\n",
    "# TODO: Run more events\n",
    "nevents = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Numba\n",
      "Using SU(3)\n",
      "Using double precision\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# I need to add this line to ask resources from a specific GPU, which is free. Our GPU server has no queing system\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "os.environ[\"MY_NUMBA_TARGET\"] = \"numba\"\n",
    "# os.environ[\"MY_NUMBA_TARGET\"] = \"cuda\"\n",
    "os.environ[\"PRECISION\"] = \"double\"\n",
    "os.environ['GAUGE_GROUP'] = su_group\n",
    "\n",
    "# Import relevant modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Glasma modules\n",
    "import curraun.core as core\n",
    "import curraun.mv as mv\n",
    "import curraun.initial as initial\n",
    "initial.DEBUG = False\n",
    "\n",
    "# Don't print accuracy check \n",
    "import curraun.initial_su3 as initial_su3\n",
    "initial_su3.DEBUG = False\n",
    "\n",
    "import curraun.su as su\n",
    "from curraun.numba_target import use_cuda\n",
    "if use_cuda:\n",
    "    from numba import cuda\n",
    "\n",
    "import curraun.su as su\n",
    "# import curraun.lc_gauge as lc_gauge\n",
    "import curraun.lc_gauge_zindep as lc_gauge\n",
    "# Gauge transformation for U_-\n",
    "lc_gauge.LCDEBUG = False\n",
    "\n",
    "# Number of colors\n",
    "Nc = su.NC\n",
    "# Dimension of algebra \n",
    "Dg = su.GROUP_ELEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress various horribly long warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Simulation routine\n",
    "def simulate(): \n",
    "    output = {}\n",
    "    # Derived parameters\n",
    "    a = L / N\n",
    "    E0 = N / L * hbarc\n",
    "    DT = 1.0 / DTS\n",
    "    maxt = int(tau_sim / a * DTS)\n",
    "\n",
    "    #TODO: for testing only, remove after testing\n",
    "    mv.set_seed(24)\n",
    "\n",
    "    # Initialize Glasma fields\n",
    "    s = core.Simulation(N, DT, g)\n",
    "\n",
    "    va = mv.wilson(s, mu=mu / E0, m=ir / E0, uv=uv / E0, num_sheets=ns)\n",
    "    vb = mv.wilson(s, mu=mu / E0, m=ir / E0, uv=uv / E0, num_sheets=ns)\n",
    "    initial.init(s, va, vb)\n",
    "\n",
    "    # Initialize LC gauge transformation\n",
    "    nplus = maxt//DTS\n",
    "    lc = lc_gauge.LCGaugeTransf(s, nplus)\n",
    "\n",
    "    # Plus gauge link\n",
    "    # xplus=0 is not included\n",
    "    uplus_lc = su.GROUP_TYPE(np.zeros((maxt//DTS-1, N, su.GROUP_ELEMENTS)))\n",
    "    vlc = su.GROUP_TYPE(np.zeros((nplus, nplus*N, su.GROUP_ELEMENTS)))\n",
    "    uplus_temp = su.GROUP_TYPE(np.zeros((maxt//DTS-1, N, su.GROUP_ELEMENTS)))\n",
    "\n",
    "    # Plus gauge link\n",
    "    uplus_lc_test = su.GROUP_TYPE(np.zeros((maxt//DTS-1, N, Dg)))\n",
    "    vlc_test = su.GROUP_TYPE([[su.unit() for y in range(N)] for xplus in range (maxt//DTS)])\n",
    "    vlc_test_out = su.GROUP_TYPE(np.zeros((nplus, nplus, N, su.GROUP_ELEMENTS)))\n",
    "    uplus_temp_test = su.GROUP_TYPE(np.zeros((maxt//DTS-1, N, Dg)))\n",
    "\n",
    "    if lc_gauge.LCDEBUG:\n",
    "        # xplus=0 in not included\n",
    "        # also, xplus=maxt is not included\n",
    "        uminus_lc = su.GROUP_TYPE(np.zeros((maxt//DTS-2, N, su.GROUP_ELEMENTS)))\n",
    "\n",
    "    with tqdm(total=maxt) as pbar:\n",
    "        for t in range(maxt):            \n",
    "            # Evolve Glasma fields\n",
    "            core.evolve_leapfrog(s)\n",
    "\n",
    "            if t%DTS == 0:\n",
    "                # GPU\n",
    "                xplus = t//DTS\n",
    "                lc.evolve_lc(xplus)\n",
    "\n",
    "                if xplus!= 0:\n",
    "                    uplus_lc[xplus-1] = lc.up_lc.copy()\n",
    "                    uplus_temp[xplus-1] = lc.up_temp.copy()\n",
    "\n",
    "                if lc_gauge.LCDEBUG:\n",
    "                    if xplus != (maxt//DTS-1):\n",
    "                        uminus_lc[xplus-1] = lc.um_lc.copy()\n",
    "                    \n",
    "                vlc[xplus] = lc.vlc1.copy()\n",
    "\n",
    "                # CPU\n",
    "                u1 = s.u1.copy()\n",
    "                u0 = s.u0.copy()\n",
    "                \n",
    "                ux_act = u1[:,0,:].reshape(N,N,Dg)\n",
    "                ux_prev = u0[:,0,:].reshape(N,N,Dg)\n",
    "   \n",
    "                # We construct the u_+ links over the x^+ axis in a y transverse lattice\n",
    "                up_temp_test = su.GROUP_TYPE(np.zeros((N,Dg)))\n",
    "                \n",
    "                for ix in range(maxt//DTS):\n",
    "                    for y in range(N):\n",
    "                        if ix > (t//DTS): # We construct the gauge operator\n",
    "                            v_prev = vlc_test[ix, y]\n",
    "                            vlc_test[ix, y] = lc_gauge.gauge_transformation_operator(ux_act[2*ix-t//DTS,y], v_prev) \n",
    "                            \n",
    "                        elif ix == (t//DTS) and ix != 0:\n",
    "                            up_temp_test[y] = lc_gauge.get_plus_links(ux_prev[t//DTS,y])\n",
    "                            uplus_temp_test[t//DTS-1, y] = up_temp_test[y]            \n",
    "\n",
    "                            uplus_lc_test[xplus-1, y, :] = lc_gauge.act_on_links(up_temp_test[y], vlc_test[ix, y], vlc_test[ix-1, y])\n",
    "\n",
    "                vlc_test_out[xplus] = vlc_test\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    if use_cuda:\n",
    "        cuda.current_context().deallocations.clear()\n",
    "\n",
    "    output[\"nplus\"] = nplus\n",
    "\n",
    "    output[\"uplus_lc\"] = uplus_lc\n",
    "    output[\"uplus_temp\"] = uplus_temp \n",
    "    output[\"vlc\"] = vlc \n",
    "\n",
    "    output[\"uplus_lc_test\"] = uplus_lc_test\n",
    "    output[\"uplus_temp_test\"] = uplus_temp_test\n",
    "    output[\"vlc_test\"] = vlc_test_out\n",
    "\n",
    "    if lc_gauge.LCDEBUG:  \n",
    "        output[\"uminus_lc\"] = uminus_lc\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:13<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "output = simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplus = output[\"nplus\"]\n",
    "\n",
    "uplus_lc = output[\"uplus_lc\"]\n",
    "uplus_temp = output[\"uplus_temp\"]\n",
    "vlc = output[\"vlc\"]\n",
    "\n",
    "uplus_lc_test = output[\"uplus_lc_test\"]\n",
    "uplus_temp_test = output[\"uplus_temp_test\"]\n",
    "vlc_test = output[\"vlc_test\"]\n",
    "\n",
    "if lc_gauge.LCDEBUG:\n",
    "    uminus_lc = output[\"uminus_lc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uplus_temp == uplus_temp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uplus_lc == uplus_lc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "       0.+0.j])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uplus_lc[0, 1, :] - uplus_lc_test[0, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uplus_lc-uplus_lc_test).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "       [[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "       [[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "       [[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "       [[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlc_r = vlc.reshape(nplus, nplus, N, Dg)\n",
    "vlc_r == vlc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]\n",
    "\n",
    "for t in range(vlc_test.shape[0]):\n",
    "    for x in range(vlc_test.shape[1]):\n",
    "        for y in range(vlc_test.shape[2]):\n",
    "            if x > t:\n",
    "                if (vlc_r[t, x, y, :]-vlc_test[t, x, y, :]).all():\n",
    "                    print(x, y)\n",
    "                    print(vlc_r[t, x, y, :]-vlc_test[t, x, y, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
